{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213402ac",
   "metadata": {},
   "source": [
    "## 1. Imports e ConfiguraÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Project modules\n",
    "from src.features import criar_variaveis_derivadas\n",
    "from src.config import DATA_PATH, MODELS_PATH, TEXT_PATH, FIGURES_PATH\n",
    "from src.model_versioning import ModelVersionManager, ModelMetrics, log_evaluation\n",
    "\n",
    "# Estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Todos os imports carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8b5bc",
   "metadata": {},
   "source": [
    "## 2. Carregamento e PreparaÃ§Ã£o de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"ðŸ“Š Dados carregados: {df.shape[0]} registros, {df.shape[1]} variÃ¡veis\")\n",
    "print(f\"\\nPrimeiras linhas:\\n{df.head()}\")\n",
    "print(f\"\\nTipos de dados:\\n{df.dtypes}\")\n",
    "print(f\"\\nValores faltantes:\\n{df.isnull().sum().sum()} faltantes no total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5d700",
   "metadata": {},
   "source": [
    "## 3. Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar engenharia de features\n",
    "df = criar_variaveis_derivadas(df)\n",
    "\n",
    "print(f\"âœ… Features criadas: {df.shape[1]} variÃ¡veis disponÃ­veis\")\n",
    "print(f\"\\nNovas colunas: {[col for col in df.columns if col not in ['Attrition_Flag', 'Customer_Age']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e12020",
   "metadata": {},
   "source": [
    "## 4. SeleÃ§Ã£o de Features e PreparaÃ§Ã£o da Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-feature baseline (padrÃ£o de produÃ§Ã£o)\n",
    "features = [\n",
    "    'Customer_Age', 'Dependent_count', 'Credit_Limit',\n",
    "    'Total_Trans_Amt', 'Total_Trans_Ct', 'Ticket_Medio',\n",
    "    'Gasto_Medio_Mensal', 'Rotativo_Ratio', 'Score_Relacionamento',\n",
    "    'LTV_Proxy', 'Caiu_Valor', 'Caiu_Transacoes'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Attrition_Flag\"].map({\"Attrited Customer\": 1, \"Existing Customer\": 0})\n",
    "\n",
    "print(f\"âœ… Features selecionadas: {len(features)}\")\n",
    "print(f\"âœ… Target (churn): {y.sum()} positivos ({y.sum()/len(y):.1%}) | {len(y)-y.sum()} negativos ({(1-y.sum()/len(y)):.1%})\")\n",
    "print(f\"\\nDistribuiÃ§Ã£o alvo:\\n{y.value_counts(normalize=True).sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0211e90",
   "metadata": {},
   "source": [
    "## 5. Split Treino/Teste com EstratificaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26567686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # MantÃ©m proporÃ§Ã£o de churn em treino e teste\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dados divididos com sucesso\")\n",
    "print(f\"\\nTreino: {len(X_train)} registros\")\n",
    "print(f\"  - Churn: {y_train.sum()} ({y_train.sum()/len(y_train):.1%})\")\n",
    "print(f\"\\nTeste: {len(X_test)} registros\")\n",
    "print(f\"  - Churn: {y_test.sum()} ({y_test.sum()/len(y_test):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277a052",
   "metadata": {},
   "source": [
    "## 6. Treinamento do Modelo - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiperparÃ¢metros otimizados\n",
    "lgbm_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'is_unbalanced': True,           # Dados desbalanceados\n",
    "    'class_weight': 'balanced',       # EstratÃ©gia: nÃ£o usar SMOTE\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Treinar modelo\n",
    "model = lgb.LGBMClassifier(**lgbm_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… Modelo LightGBM treinado com sucesso!\")\n",
    "print(f\"\\nHiperparÃ¢metros: {lgbm_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c699d",
   "metadata": {},
   "source": [
    "## 7. AvaliaÃ§Ã£o Compreensiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrediÃ§Ãµes\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular mÃ©tricas\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics_dict = {\n",
    "    'auc': auc_score,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1\n",
    "}\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"=\"*50)\n",
    "print(\"MÃ‰TRICAS DE AVALIAÃ‡ÃƒO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ðŸŽ¯ AUC-ROC:      {auc_score:.4f}\")\n",
    "print(f\"ðŸŽ¯ AcurÃ¡cia:     {accuracy:.4f}\")\n",
    "print(f\"ðŸŽ¯ PrecisÃ£o:     {precision:.4f}\")\n",
    "print(f\"ðŸŽ¯ Recall:       {recall:.4f}\")\n",
    "print(f\"ðŸŽ¯ F1-Score:     {f1:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22e047",
   "metadata": {},
   "source": [
    "## 8. ValidaÃ§Ã£o Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(\n",
    "    model, X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=['roc_auc', 'accuracy', 'precision', 'recall', 'f1'],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Resumo de CV\n",
    "print(\"\\nðŸ“Š VALIDAÃ‡ÃƒO CRUZADA (5-fold)\")\n",
    "print(f\"AUC-ROC:  {cv_results['test_roc_auc'].mean():.4f} (+/- {cv_results['test_roc_auc'].std():.4f})\")\n",
    "print(f\"AcurÃ¡cia: {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std():.4f})\")\n",
    "print(f\"PrecisÃ£o: {cv_results['test_precision'].mean():.4f} (+/- {cv_results['test_precision'].std():.4f})\")\n",
    "print(f\"Recall:   {cv_results['test_recall'].mean():.4f} (+/- {cv_results['test_recall'].std():.4f})\")\n",
    "print(f\"F1:       {cv_results['test_f1'].mean():.4f} (+/- {cv_results['test_f1'].std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ab61f",
   "metadata": {},
   "source": [
    "## 9. AnÃ¡lise de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualizar\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(feature_importance_df)))\n",
    "ax.barh(feature_importance_df['feature'], feature_importance_df['importance'], color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('ImportÃ¢ncia Relativa', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Feature Importance - LightGBM', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Adicionar valores\n",
    "for i, v in enumerate(feature_importance_df['importance']):\n",
    "    ax.text(v + 0.5, i, f'{v:.1f}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH / \"feature_importance_reference.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Top 5 Features:\")\n",
    "print(feature_importance_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17053a88",
   "metadata": {},
   "source": [
    "## 10. Matriz de ConfusÃ£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusÃ£o\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Existing', 'Attrited'],\n",
    "            yticklabels=['Existing', 'Attrited'],\n",
    "            cbar_kws={'label': 'Contagem'})\n",
    "ax.set_xlabel('Predito', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Real', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Matriz de ConfusÃ£o - LightGBM', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH / \"confusion_matrix_reference.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… AnÃ¡lise:\")\n",
    "print(f\"  True Negatives (TN):  {cm[0,0]}\")\n",
    "print(f\"  False Positives (FP): {cm[0,1]}\")\n",
    "print(f\"  False Negatives (FN): {cm[1,0]}\")\n",
    "print(f\"  True Positives (TP):  {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6c58b",
   "metadata": {},
   "source": [
    "## 11. Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf71ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=3, label=f'LightGBM (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance (AUC = 0.50)')\n",
    "ax.fill_between(fpr, tpr, alpha=0.2, color='darkorange')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ROC Curve - LightGBM', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_PATH / \"roc_curve_reference.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… AUC-ROC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd494f",
   "metadata": {},
   "source": [
    "## 12. Classification Report Detalhado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2775773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred,\n",
    "                                    target_names=['Existing Customer', 'Attrited Customer'],\n",
    "                                    digits=4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f721fbeb",
   "metadata": {},
   "source": [
    "## 13. Model Versioning e Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25180cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize version manager\n",
    "manager = ModelVersionManager(MODELS_PATH)\n",
    "\n",
    "# Create metrics object\n",
    "model_metrics = ModelMetrics(\n",
    "    algorithm='lgbm',\n",
    "    version=None,  # Auto-assigned\n",
    "    auc=metrics_dict['auc'],\n",
    "    accuracy=metrics_dict['accuracy'],\n",
    "    precision=metrics_dict['precision'],\n",
    "    recall=metrics_dict['recall'],\n",
    "    f1=metrics_dict['f1'],\n",
    "    notes=\"12-feature baseline with class_weight='balanced', 5-fold CV\"\n",
    ")\n",
    "\n",
    "# Save model with versioning\n",
    "model_path = manager.save_model(\n",
    "    model=model,\n",
    "    algorithm='lgbm',\n",
    "    metrics=model_metrics,\n",
    "    is_production=True  # Also save as model_final.pkl\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Modelo salvo com sucesso!\")\n",
    "print(f\"   VersÃ£o: {model_metrics.version}\")\n",
    "print(f\"   Caminho: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079d4ac",
   "metadata": {},
   "source": [
    "## 14. Log de AvaliaÃ§Ã£o Detalhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log evaluation\n",
    "eval_file = log_evaluation(\n",
    "    output_dir=TEXT_PATH,\n",
    "    algorithm=f\"lgbm_{model_metrics.version}\",\n",
    "    metrics=metrics_dict,\n",
    "    report_text=class_report\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… AvaliaÃ§Ã£o registrada em: {eval_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949fb8f",
   "metadata": {},
   "source": [
    "## 15. HistÃ³rico de VersÃµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10053287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all versions\n",
    "versions_df = manager.list_models()\n",
    "print(\"\\nðŸ“Š HistÃ³rico de VersÃµes:\")\n",
    "print(versions_df.to_string())\n",
    "\n",
    "# Best model\n",
    "best_model_data = versions_df.loc[versions_df['auc'].idxmax()]\n",
    "print(f\"\\nðŸ† Melhor modelo (por AUC):\")\n",
    "print(f\"   {best_model_data['filename']} - AUC: {best_model_data['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9c044",
   "metadata": {},
   "source": [
    "## 16. RecomendaÃ§Ãµes de NegÃ³cio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMENDAÃ‡Ã•ES DE NEGÃ“CIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸŽ¯ PERFORMANCE DO MODELO:\n",
    "   - AUC: {metrics_dict['auc']:.1%} (Excelente: >0.9)\n",
    "   - Recall: {metrics_dict['recall']:.1%} (Captura {metrics_dict['recall']:.1%} dos casos de churn)\n",
    "   - PrecisÃ£o: {metrics_dict['precision']:.1%} (Quando prediz churn, acerta em {metrics_dict['precision']:.1%})\n",
    "\n",
    "ðŸ’¡ AÃ‡Ã•ES RECOMENDADAS:\n",
    "   1. Usar modelo em produÃ§Ã£o para identificar clientes em risco\n",
    "   2. Focar em estratÃ©gias de retenÃ§Ã£o para top {metrics_dict['recall']:.0%} de casos\n",
    "   3. Features crÃ­ticas: Caiu_Valor, Caiu_Transacoes, Gasto_Medio_Mensal\n",
    "   4. Implementar monitoramento contÃ­nuo (data drift)\n",
    "   5. A/B testar estratÃ©gias de retenÃ§Ã£o por segment\n",
    "\n",
    "ðŸ“Š PRÃ“XIMOS PASSOS:\n",
    "   âœ“ Testar em webapp: streamlit run webapp/app.py\n",
    "   âœ“ Comparar com XGBoost e Random Forest\n",
    "   âœ“ Fazer SHAP analysis para explicabilidade\n",
    "   âœ“ Tunar hiperparÃ¢metros com Optuna/GridSearch\n",
    "   âœ“ Implantar em ambiente de produÃ§Ã£o\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
